<!DOCTYPE html>
<html lang="en-US">
    <head>
        <meta charset="utf-8"> 
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <meta name="author" content="Rongfei" />
        <meta name="copyright" content="Rongfei" />

        <meta property="og:type" content="article" />
        <meta name="twitter:card" content="summary">

<meta name="keywords" content="scrapy, python, tools, " />

<meta property="og:title" content="scrapy基础 "/>
<meta property="og:url" content="/drafts/scrapyji-chu.html" />
<meta property="og:description" content="" />
<meta property="og:site_name" content="LearnDevOps" />
<meta property="og:article:author" content="Rongfei" />
<meta property="og:article:published_time" content="2016-05-03T11:26:00+08:00" />
<meta name="twitter:title" content="scrapy基础 ">
<meta name="twitter:description" content="">

        <title>scrapy基础  · LearnDevOps
</title>
        <link href="//netdna.bootstrapcdn.com/twitter-bootstrap/2.3.2/css/bootstrap-combined.min.css" rel="stylesheet">
        <link href="//netdna.bootstrapcdn.com/font-awesome/4.0.1/css/font-awesome.css" rel="stylesheet">
        <link rel="stylesheet" type="text/css" href="/theme/css/pygments.css" media="screen">
        <link rel="stylesheet" type="text/css" href="/theme/tipuesearch/tipuesearch.css" media="screen">
        <link rel="stylesheet" type="text/css" href="/theme/css/elegant.css" media="screen">
        <link rel="stylesheet" type="text/css" href="/theme/css/custom.css" media="screen">
    </head>
    <body>
        <div id="content-sans-footer">
        <div class="navbar navbar-static-top">
            <div class="navbar-inner">
                <div class="container-fluid">
                    <a class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                    </a>
                    <a class="brand" href="/"><span class=site-name>LearnDevOps</span></a>
                    <div class="nav-collapse collapse">
                        <ul class="nav pull-right top-menu">
                            <li ><a href="">Home</a></li>
                            <li ><a href="/pages/about-me.html">About Me</a></li>
                            <li ><a href="/categories.html">Categories</a></li>
                            <li ><a href="/tags.html">Tags</a></li>
                            <li ><a href="/archives.html">Archives</a></li>
                            <li><form class="navbar-search" action="/search.html" onsubmit="return validateForm(this.elements['q'].value);"> <input type="text" class="search-query" placeholder="Search" name="q" id="tipue_search_input"></form></li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>
        <div class="container-fluid">
            <div class="row-fluid">
                <div class="span1"></div>
                <div class="span10">
<article>
<div class="row-fluid">
    <header class="page-header span10 offset2">
    <h1><a href="/drafts/scrapyji-chu.html"> scrapy基础  </a></h1>
    </header>
</div>

<div class="row-fluid">
        <div class="span8 offset2 article-content">

            
            <!-- # Status: published -->

<!-- TOC depthFrom:1 depthTo:6 withLinks:1 updateOnSave:1 orderedList:0 -->

<ul>
<li><a href="#自己编写爬虫-crawlspider">自己编写爬虫 CrawlSpider</a></li>
<li><a href="#代理ip">代理ip</a></li>
<li><a href="#request-和-response的区别">request 和 response的区别</a></li>
<li><a href="#selector-和-htmlselect">selector 和 htmlselect</a></li>
<li><a href="#spiders">spiders</a></li>
<li><a href="#links">links</a></li>
<li><a href="#settings">settings</a></li>
<li><a href="#常用的settings">常用的settings</a></li>
<li><a href="#spidersrule">spiders.Rule</a><ul>
<li><a href="#linkextractor">LinkExtractor</a></li>
</ul>
</li>
</ul>
<!-- /TOC -->

<h1 id="crawlspider">CrawlSpider</h1>
<p>1.导入 scrapy.spiders.CrawlSpider
2.自己编写爬虫类继承自CrawlSpider
3.自定义的爬虫类中需要有：
  name = &lsquo;定义spider名字的字符串(string),名字且是唯一的&rsquo;
  allowed_domains ＝ [&lsquo;可选。包含了spider允许爬取的域名(domain)列表(list),当 OffsiteMiddleware 启用时， 域名不在列表中的URL不会被跟进。&rsquo;]
  start_urls = [&lsquo;URL列表。当没有制定特定的URL时，spider将从该列表中开始进行爬取。&rsquo;] def parse(request): 默认处理爬回来的页面内容</p>
<h1 id="ip">代理ip</h1>
<p><a href="http://www.xicidaili.com/">http://www.xicidaili.com/</a></p>
<h1 id="request-response">request 和 response的区别</h1>
<p>scrapy.http.Request scrapy.http.request
  scrapy.http.Response  scrapy.http.response</p>
<p>Scrapy使用 Request 和 Response 对象爬取web站点。
  一般来说，Request 对象在spiders中被生成并且最终传递到 下载器(Downloader)，下载器对其进行处理并返回一个 Response 对象， Response 对象还会返回到生成request的spider中</p>
<h1 id="selector-htmlselect">selector 和 htmlselect</h1>
<p>scrapy.selector.HtmlXPathSelector
scrapy.selector.XPathSelector
scrapy.selector.Selector
scrapy.selector.SelectorList</p>
<h1 id="spiders">spiders</h1>
<p>scrapy.spiders.Spider
scrapy.spiders.BaseSpider
scrapy.spiders.CrawlSpider
scrapy.spiders.Request
scrapy.spiders.Rule
scrapy.spiders.logging
scrapy.spiders.spiders
scrapy.spiders.sitemap</p>
<h1 id="links">links</h1>
<p>scrapy.linkextractors.LinkExtractor</p>
<h1 id="settings">settings</h1>
<ul>
<li>
<p>BOT_NAME   默认: &lsquo;scrapybot&rsquo;
Scrapy项目实现的bot名字(也项目名称)。 通过这个名称来构造默认 User-Agent，同时也用来log。当您使用 startproject 命令创建项目时其也被自动赋值。</p>
</li>
<li>
<p>CONCURRENT_ITEMS 默认: 100
Item Processor(即 Item Pipeline) 同时处理(每个response的)item的最大值</p>
</li>
<li>
<p>CONCURRENT_REQUESTS 默认: 16
Scrapy downloader 并发请求(concurrent requests)的最大值</p>
</li>
<li>
<p>CONCURRENT_REQUESTS_PER_DOMAIN 默认: 8
对单个网站进行并发请求的最大值</p>
</li>
<li>
<p>CONCURRENT_REQUESTS_PER_IP默认: 0
对单个IP进行并发请求的最大值。如果非0，则忽略 CONCURRENT_REQUESTS_PER_DOMAIN 设定， 使用该设定。 也就是说，并发限制将针对IP，而不是网站。该设定也影响 DOWNLOAD_DELAY: 如果 CONCURRENT_REQUESTS_PER_IP 非0，下载延迟应用在IP而不是网站上。</p>
</li>
<li>
<p>DEFAULT_ITEM_CLASS 默认: &lsquo;scrapy.item.Item&rsquo;</p>
</li>
</ul>
<p>the Scrapy shell 中实例化item使用的默认类。</p>
<ul>
<li>DEFAULT_REQUEST_HEADERS 默认:</li>
</ul>
<div class="codehilite" style="background: #f8f8f8"><pre style="line-height: 125%"><span></span>{
    &#39;Accept&#39;: &#39;text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8&#39;,
    &#39;Accept-Language&#39;: &#39;en&#39;,
}
</pre></div>


<p>Scrapy HTTP Request使用的默认header。由DefaultHeadersMiddleware 产生。</p>
<ul>
<li>
<p>DEPTH_LIMIT 默认: 0
爬取网站最大允许的深度(depth)值。如果为0，则没有限制。</p>
</li>
<li>
<p>DOWNLOAD_DELAY 默认: 0
下载器在下载同一个网站下一个页面前需要等待的时间。该选项可以用来限制爬取速度， 减轻服务器压力。同时也支持小数:</p>
</li>
</ul>
<div class="codehilite" style="background: #f8f8f8"><pre style="line-height: 125%"><span></span>DOWNLOAD_DELAY = 0.25    # 250 ms of delay
</pre></div>


<p>该设定影响(默认启用的) RANDOMIZE_DOWNLOAD_DELAY 设定。 默认情况下，Scrapy在两个请求间不等待一个固定的值， 而是使用0.5到1.5之间的一个随机值 * DOWNLOAD_DELAY 的结果作为等待间隔。</p>
<p>当 CONCURRENT_REQUESTS_PER_IP 非0时，延迟针对的是每个ip而不是网站。</p>
<p>另外您可以通过spider的 download_delay 属性为每个spider设置该设定。</p>
<ul>
<li>DOWNLOAD_HANDLERS 默认: {}</li>
</ul>
<p>保存项目中启用的下载处理器(request downloader handler)的字典。 例子请查看 DOWNLOAD_HANDLERS_BASE 。</p>
<ul>
<li>DOWNLOAD_HANDLERS_BASE 默认:</li>
</ul>
<p>{
    &lsquo;file&rsquo;: &lsquo;scrapy.core.downloader.handlers.file.FileDownloadHandler&rsquo;,
    &lsquo;http&rsquo;: &lsquo;scrapy.core.downloader.handlers.http.HttpDownloadHandler&rsquo;,
    &lsquo;https&rsquo;: &lsquo;scrapy.core.downloader.handlers.http.HttpDownloadHandler&rsquo;,
    &lsquo;s3&rsquo;: &lsquo;scrapy.core.downloader.handlers.s3.S3DownloadHandler&rsquo;,
}</p>
<p>保存项目中默认启用的下载处理器(request downloader handler)的字典。 永远不要在项目中修改该设定，而是修改 DOWNLOADER_HANDLERS 。</p>
<p>如果需要关闭上面的下载处理器，您必须在项目中的 DOWNLOAD_HANDLERS 设定中设置该处理器，并为其赋值为 None 。 例如，关闭文件下载处理器:</p>
<p>DOWNLOAD_HANDLERS = {
    &lsquo;file&rsquo;: None,
}</p>
<p>DOWNLOAD_TIMEOUT</p>
<p>默认: 180</p>
<p>下载器超时时间(单位: 秒)。</p>
<h1 id="settings_1">常用的settings</h1>
<ul>
<li>DOWNLOAD_DELAY 默认: 0
限制爬取速度， 减轻服务器压力。同时也支持小数:</li>
<li>
<p>CONCURRENT_REQUESTS 默认: 16
Scrapy downloader 并发请求(concurrent requests)的最大值</p>
</li>
<li>
<p>CONCURRENT_REQUESTS_PER_DOMAIN 默认: 8
对单个网站进行并发请求的最大值</p>
</li>
<li>
<p>COOKIES_ENABLED = False # 禁用cookie</p>
</li>
<li>RETRY_ENABLED = False # 禁止重试</li>
<li>DOWNLOAD_TIMEOUT = 15 #减小下载超时</li>
<li>REDIRECT_ENABLED = False #关闭重定向</li>
<li>AJAXCRAWL_ENABLED = True #启用 “Ajax Crawlable Pages” 爬取</li>
</ul>
<h1 id="spidersrule">spiders.Rule</h1>
<div class="codehilite" style="background: #f8f8f8"><pre style="line-height: 125%"><span></span>scrapy.spiders.Rule(
  link_extractor,
  callback=None,
  cb_kwargs=None,
  follow=None,
  process_links=None,
  process_request=None)
</pre></div>


<ul>
<li>参数解释
  &ndash; link_extractor 是一个 Link Extractor 对象。 其定义了如何从爬取到的页面提取链接。</li>
</ul>
<p>&ndash; callback 是通过反射来调用spider中的同名函数。 从link_extractor中每获取到一个链接将会调用该函数。该回调函数接受一个response作为其第一个参数， 并返回一个包含Item以及(或)Request对象(或者这两者的子类)的列表(list)。</p>
<p>&ndash; cb_kwargs 传递给回调函数的参数(keyword argument 字典类型)支持<em>key </em>*wkeys</p>
<p>&ndash; follow 是一个布尔(boolean)值，指定了根据该规则从response提取的链接是否需要跟进。如果 callback 为None， follow 默认设置为 True ，否则默认为 False</p>
<p>&ndash; process_links 是一个callable或string(该spider中同名的函数将会被调用)。 从link_extractor中获取到链接列表时将会调用该函数。该方法主要用来过滤。</p>
<p>&ndash; process_request 是一个callable或string(该spider中同名的函数将会被调用)。 该规则提取到每个request时都会调用该函数。该函数必须返回一个request或者None。 (用来过滤request)</p>
<h2 id="linkextractor">LinkExtractor</h2>
<p>Link Extractors 是那些目的仅仅是从网页(scrapy.http.Response 对象)中抽取最终将会被follow链接的对象
通过scrapy.linkextractors import LinkExtractor 接口创建自己的Link Extractor来满足需求
每个link extractor有唯一的公共方法是 extract_links ,它接收一个 Response 对象,并返回一个 scrapy.link.Link 对象｡Link Extractors,要实例化一次并且 extract_links 方法会根据不同的response调用多次提取链接｡
Link Extractors主要是在 CrawlSpider类中使用Rule来建一套规则提取url,但你也可以用它在你的Spider中, 即使你不是从 CrawlSpider 继承的子类, 因为它的目的很简单: 提取链接｡
Scrapy提供的Link Extractor类在 scrapy.linkextractors 模块中｡ 默认的link extractor是 LinkExtractor , 其实就是 LxmlLinkExtractor:</p>
<div class="codehilite" style="background: #f8f8f8"><pre style="line-height: 125%"><span></span>scrapy.linkextractors.lxmlhtml.LxmlLinkExtractor(
  allow=(),
  deny=(),
  allow_domains=(),
  deny_domains=(),
  deny_extensions=None,
  restrict_xpaths=(),
  restrict_css=(),
  tags=(&#39;a&#39;, &#39;area&#39;),
  attrs=(&#39;href&#39;, ),
  canonicalize=True,
  unique=True,
  process_value=None)
</pre></div>


<p>&ndash; unique (boolean) – 是一个布尔值,指定是否重复过滤, 应用于提取链接</p>
<h1 id="user-agent">查看浏览器USER-AGENT</h1>
<p><code>navigator.userAgent</code>
console.log(navigator.userAgent)</p>
<p>＃ list
1. 随机USSER-AGENT
2. 抓取指定页面
3. 分配任务给指定IP抓取
4. 指定页面抓取频率
5. parse 页面结构化
6. 存储
7. PhantomJs ＃js加载的页面
8. 登录抓取</p>
            
            
            <hr/>
        </div>
        <section>
        <div class="span2" style="float:right;font-size:0.9em;">
            <h4>Published</h4>
            <time pubdate="pubdate" datetime="2016-05-03T11:26:00+08:00">5月 3, 2016</time>
            <h4>Category</h4>
            <a class="category-link" href="/categories.html#tools-ref">tools</a>
            <h4>Tags</h4>
            <ul class="list-of-tags tags-in-article">
                <li><a href="/tags.html#python-ref">python
                    <span>7</span>
</a></li>
                <li><a href="/tags.html#scrapy-ref">scrapy
</a></li>
            </ul>
        </div>
        </section>
</div>

<!-- 多说评论框 start -->
<div class="ds-thread" data-thread-key="scrapy基础" data-title="scrapy基础" data-url="http://blog.pyshell.cn/drafts/scrapyji-chu.html"></div>
<!-- 多说评论框 end -->
<!-- 多说公共JS代码 start (一个网页只需插入一次) -->
<script type="text/javascript">
var duoshuoQuery = {short_name:"devops"};
	(function() {
		var ds = document.createElement('script');
		ds.type = 'text/javascript';ds.async = true;
		ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
		ds.charset = 'UTF-8';
		(document.getElementsByTagName('head')[0] 
		 || document.getElementsByTagName('body')[0]).appendChild(ds);
	})();
	</script>
<!-- 多说公共JS代码 end -->
<!-- baidu tongji   -->
<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?b6fb6111b823b418109202b642b4a62b";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>

<!-- baidu tongji  end -->

</article>
                </div>
                <div class="span1"></div>
            </div>
        </div>
        <div id="push"></div>
    </div>
<footer>
<div id="footer">
    <ul class="footer-content">
        <li class="elegant-power">Powered by <a href="http://getpelican.com/" title="Pelican Home Page">Pelican</a>. Theme: <a href="http://oncrashreboot.com/pelican-elegant" title="Theme Elegant Home Page">Elegant</a> by <a href="http://oncrashreboot.com" title="Talha Mansoor Home Page">Talha Mansoor</a></li>
    </ul>
</div>
</footer>            <script src="http://code.jquery.com/jquery.min.js"></script>
        <script src="//netdna.bootstrapcdn.com/twitter-bootstrap/2.3.2/js/bootstrap.min.js"></script>
        <script>
            function validateForm(query)
            {
                return (query.length > 0);
            }
        </script>

    
    </body>
    <!-- Theme: Elegant built for Pelican
    License : http://oncrashreboot.com/pelican-elegant -->
</html>